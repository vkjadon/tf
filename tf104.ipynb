{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYuKHTaoGXbxLcGJMwX7aX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjadon/tf/blob/main/tf104.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tensor Flow Tutorial"
      ],
      "metadata": {
        "id": "L_yX6G6Y5npt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E2mwEZwY8DP",
        "outputId": "be5e8498-b783-4589-c1cd-ab7bbd5cb4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load a dataset\n",
        "Load and prepare the MNIST dataset. Convert the sample data from integers to floating-point numbers:"
      ],
      "metadata": {
        "id": "-HFT39L3aOsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "EfzMenHeaRnt"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build a machine learning model\n",
        "Build a tf.keras.Sequential model by stacking layers."
      ],
      "metadata": {
        "id": "t2Z5lyLPacq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "ByX4S_1Eaz4x"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model\n",
        "In general, any mathematical construct that processes input data and returns output. Phrased differently, a model is the set of parameters and structure needed for a system to make predictions. In supervised machine learning, a model takes an example as input and infers a prediction as output. Within supervised machine learning, models differ somewhat. For example:\n",
        "\n",
        "- A linear regression model consists of a set of weights and a bias.\n",
        "- A neural network model consists of:\n",
        " - A set of hidden layers, each containing one or more neurons.\n",
        " - The weights and bias associated with each neuron.\n",
        "- A decision tree model consists of:\n",
        " - The shape of the tree; that is, the pattern in which the conditions and leaves are connected.\n",
        " - The conditions and leaves.\n",
        "\n",
        "You can save, restore, or make copies of a model.\n"
      ],
      "metadata": {
        "id": "CWwmD3IJ4Ceg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(x_train[:1]).numpy()\n",
        "#predictions = model(x_train[:1])\n",
        "predictions\n",
        "#predictions.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHVfTzVcbCuz",
        "outputId": "36b8c786-312f-414a-d70f-dd728b4dee3e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.8583711 , -0.22419047,  0.3714502 ,  0.16061333, -0.34608722,\n",
              "        -0.89873064,  0.3707215 , -0.58198035, -0.13866244,  0.41051438]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vector of raw (non-normalized) predictions that a classification model generates, which is ordinarily then passed to a normalization function. If the model is solving a multi-class classification problem, logits typically become an input to the softmax function. The softmax function then generates a vector of (normalized) probabilities with one value for each possible class."
      ],
      "metadata": {
        "id": "6o7GKBQG3Yyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tf.nn.softmax function converts these logits to probabilities for each class:"
      ],
      "metadata": {
        "id": "JgJSpAv4bzEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hchFleB1b0QX",
        "outputId": "7ef2820e-7ce7-4a45-a34f-312c695fa0bb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2091078 , 0.0708304 , 0.12850001, 0.10407296, 0.0627019 ,\n",
              "        0.03608034, 0.12840642, 0.04952603, 0.077155  , 0.1336191 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: It is possible to bake the tf.nn.softmax function into the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output."
      ],
      "metadata": {
        "id": "LsCvua0UcJi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a loss function for training using losses.SparseCategoricalCrossentropy, which takes a vector of logits and a True index and returns a scalar loss for each example."
      ],
      "metadata": {
        "id": "NGJhdc9vcS2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "b2S7oYdBcKJ6"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loss is equal to the negative log probability of the true class: The loss is zero if the model is sure of the correct class.\n",
        "\n",
        "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.math.log(1/10) ~= 2.3."
      ],
      "metadata": {
        "id": "KUsCkDpWcZw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_P3LTnUcasy",
        "outputId": "f27f634b-d2d5-4ac7-e88e-11f21d4dd5ef"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.3220072"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you start training, configure and compile the model using Keras Model.compile. Set the optimizer class to adam, set the loss to the loss_fn function you defined earlier, and specify a metric to be evaluated for the model by setting the metrics parameter to accuracy."
      ],
      "metadata": {
        "id": "1dQggHuCdZgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bUJJ8RLbdajw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train and evaluate your model\n",
        "Use the Model.fit method to adjust your model parameters and minimize the loss:"
      ],
      "metadata": {
        "id": "rxm5y5WWdge2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3u6zZMCdh2s",
        "outputId": "b2148875-56a4-4536-c280-87e72975f047"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2956 - accuracy: 0.9147\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1453 - accuracy: 0.9569\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9677\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0877 - accuracy: 0.9727\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0743 - accuracy: 0.9762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ddec2a990>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model.evaluate method checks the models performance, usually on a \"Validation-set\" or \"Test-set\"."
      ],
      "metadata": {
        "id": "Tc7otLNOdyJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhevlo8MdzZG",
        "outputId": "d395c9a2-d80c-4a26-ad8a-84137deaef23"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0740 - accuracy: 0.9774 - 590ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07395780831575394, 0.977400004863739]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}